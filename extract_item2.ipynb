{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import webbrowser\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pprint\n",
    "import pickle\n",
    "import dask\n",
    "from dask.diagnostics import ProgressBar\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1138,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_year = 2017\n",
    "cpu_core = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1139,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fp = '/Users/dylan/Downloads/10Q_item2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load master table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1140,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_10Q = pd.read_csv(f'{data_fp}/10Q_master_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1141,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_10Q.columns = list(map(lambda _s: _s.lower(), pd_10Q.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unnamed: 0</th>\n",
       "      <th>cik</th>\n",
       "      <th>filing_date</th>\n",
       "      <th>fye</th>\n",
       "      <th>sic</th>\n",
       "      <th>ffind</th>\n",
       "      <th>file_name</th>\n",
       "      <th>n_words</th>\n",
       "      <th>n_unique_words</th>\n",
       "      <th>org_index</th>\n",
       "      <th>company_name</th>\n",
       "      <th>file_hash</th>\n",
       "      <th>file_hash_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>763950</td>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>20150930</td>\n",
       "      <td>3823</td>\n",
       "      <td>37</td>\n",
       "      <td>/Users/dylan/Downloads/10Q_item2/10-X_C_2016-2...</td>\n",
       "      <td>8127</td>\n",
       "      <td>1144</td>\n",
       "      <td>943316</td>\n",
       "      <td>UNIVERSAL DETECTION TECHNOLOGY</td>\n",
       "      <td>0001078782-16-002115_3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unnamed: 0     cik filing_date       fye   sic  ffind  \\\n",
       "0           0  763950  2016-01-04  20150930  3823     37   \n",
       "\n",
       "                                           file_name  n_words  n_unique_words  \\\n",
       "0  /Users/dylan/Downloads/10Q_item2/10-X_C_2016-2...     8127            1144   \n",
       "\n",
       "   org_index                    company_name               file_hash  \\\n",
       "0     943316  UNIVERSAL DETECTION TECHNOLOGY  0001078782-16-002115_3   \n",
       "\n",
       "   file_hash_count  \n",
       "0                1  "
      ]
     },
     "execution_count": 1142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_10Q.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILING_DATE to dt object\n",
    "pd_10Q.filing_date = pd_10Q.filing_date.apply(lambda str: datetime.strptime(str,'%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1144,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_10Q.file_name = pd_10Q.file_name.apply(lambda str: str.replace('/Users/dylan/Downloads/10Q_item2/', \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1145,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_10Q = pd_10Q.rename( columns={pd_10Q.columns[0]:'pd_10q_idx'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# helper func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble edgar link from file name.\n",
    "def get_edgar_link(fname, open_in_browser=True):\n",
    "    base_url = 'https://www.sec.gov/Archives/edgar/data/'\n",
    "    re_result = re.search('edgar_data_(\\d+)_(.+)_(\\d+).txt', fname)\n",
    "    fname_major = re_result.group(2)\n",
    "    edgar_link = base_url + re_result.group(1) + '/' + re.sub('\\-|_', '', fname_major) + '/' + fname_major + '-index.htm'\n",
    "    if open_in_browser:\n",
    "        webbrowser.open(edgar_link)\n",
    "    return edgar_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-X_C_2016-2018/2016/QTR1/20160104_10-Q_edgar_data_763950_0001078782-16-002115_3.txt\n"
     ]
    }
   ],
   "source": [
    "# an example \n",
    "# url =https://www.sec.gov/Archives/edgar/data/763950/000107878216002115/0001078782-16-002115-index.htm\n",
    "#a_file_name = pd_10Q.file_name[0]\n",
    "print(a_file_name)\n",
    "#get_edgar_link(a_file_name, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check the content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_raw_str(idx):\n",
    "    '''\n",
    "    Check an example filing by index in `pd_10K`.\n",
    "    '''\n",
    "    fname = pd_10Q.iloc[idx]['file_name']\n",
    "    print(fname)\n",
    "    with open(fname, 'r') as f:\n",
    "        print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Substitution fixes applied to list of doc strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read in files as string\n",
    "2. Remove all the exibits\n",
    "3. Remove the header section\n",
    "4. Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1149,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_m_exbibit = re.compile('<N_Exhibits>(\\d+)</N_Exhibits>')\n",
    "re_f_exbibit = re.compile('<EX-.*')\n",
    "re_f_exbibit_d = re.compile('<EX-(\\d+\\.?\\d*).*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pd_10q_idx', 'cik', 'filing_date', 'fye', 'sic', 'ffind', 'file_name',\n",
       "       'n_words', 'n_unique_words', 'org_index', 'company_name', 'file_hash',\n",
       "       'file_hash_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_10Q.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filing_str_l(year):\n",
    "    print(\"n_row:\", (pd_10Q.filing_date.dt.year==year).sum())\n",
    "    filing_str_l = []\n",
    "    pd_idx_l = []\n",
    "    idx_d = {}\n",
    "    for i, (pd_idx, row) in tqdm(enumerate(pd_10Q[pd_10Q.filing_date.dt.year==year].iterrows()), total=len(pd_10Q[pd_10Q.filing_date.dt.year==year])):\n",
    "        # read file\n",
    "        one_10q_fname = f\"{data_fp}/{row['file_name']}\"\n",
    "        with open(one_10q_fname, 'r') as f:\n",
    "            doc_str = f.read()\n",
    "        # remove exibits\n",
    "        # by construction, we know every doc has a N_Exhibits tag\n",
    "        # so the search should not return none\n",
    "        n_exb = int(re_m_exbibit.search(doc_str).group(1))\n",
    "        if n_exb > 0:\n",
    "            exb_l = list(re_f_exbibit.finditer(doc_str))\n",
    "            assert len(exb_l) == n_exb\n",
    "            doc_str = doc_str[:exb_l[0].start()]\n",
    "        # remove header\n",
    "        doc_str= doc_str[(doc_str.index('</Header>') + 9):]\n",
    "        # replace tab with space\n",
    "        doc_str = doc_str.replace('\\t', ' ')\n",
    "        # output\n",
    "        filing_str_l.append(doc_str)\n",
    "        pd_idx_l.append(pd_idx)\n",
    "        idx_d[pd_idx] = i\n",
    "    \n",
    "    return filing_str_l, pd_idx_l, idx_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_row: 19541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1151-63d3e1fa3fcd>:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i, (pd_idx, row) in tqdm(enumerate(pd_10Q[pd_10Q.filing_date.dt.year==year].iterrows()), total=len(pd_10Q[pd_10Q.filing_date.dt.year==year])):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25eae6c8acdd4cca88a63314e0c24428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=19541.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "filing_str_l, pd_idx_l, idx_d = get_filing_str_l(which_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1153,
   "metadata": {},
   "outputs": [],
   "source": [
    "spell_fixes = [\n",
    "    # the first two rules keep capitalization of letters\n",
    "    (re.compile('(i)(\\s*?t\\s*?e\\s*?m)', re.I|re.M), '\\g<1>tem'),  # i t e       m\n",
    "    (re.compile('(i)(tem\\s+?s)([^\\w\\-])', re.I|re.M), '\\g<1>tems\\g<3>'),  # item       s?\n",
    "    (re.compile('(b?\\s{,4}?u\\s{,4}?s\\s{,4}?i\\s{,4}?n\\s{,4}?e\\s{,4}?s\\s{,4}?s)(\\W)', re.I|re.M), 'business\\g<2>'),\n",
    "]     #  have no idea what is this. {0,4} btw 0,4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_sub_fixs(str_l, fix_l, squeezed=False):\n",
    "    if squeezed:\n",
    "        fix_l = [fix_l]\n",
    "    for i, doc_str in tqdm(enumerate(str_l), total=len(str_l)):\n",
    "        for re_obj, repls in fix_l:\n",
    "            doc_str = re_obj.sub(repls, doc_str)\n",
    "        str_l[i] = doc_str\n",
    "    return str_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save all processed filing_str into tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save temp results\n",
    "def save_tmp(data_fp, year_start, year_end):\n",
    "    '''\n",
    "    using both:\n",
    "        read: get_filing_str_l\n",
    "        normalize: apply_sub_fixs\n",
    "    save to tmp folder\n",
    "    '''\n",
    "    \n",
    "    if os.path.exists(f\"{data_fp}/tmp\") == False:\n",
    "        os.makedirs(f\"{data_fp}/tmp\")\n",
    "    for y in tqdm(range(year_start, year_end+1)):\n",
    "        print('-------- processing: ',y)# tqdm 1\n",
    "        filing_str_l, pd_idx_l, idx_d = get_filing_str_l(y)  # tqdm 2\n",
    "        filing_str_l = apply_sub_fixs(filing_str_l, spell_fixes)  # tqdm 3\n",
    "        with open(f\"{data_fp}/tmp/filing_{y}.data\", 'wb') as f:\n",
    "            pickle.dump([filing_str_l, pd_idx_l, idx_d], f)\n",
    "\n",
    "        tmp = pd_10Q.iloc[np.random.choice(pd_idx_l)]  # randomly listed\n",
    "       \n",
    "        assert tmp.filing_date.year == y  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1206-150cf8669853>:11: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for y in tqdm(range(year_start, year_end+1)):     # tqdm 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51243ed5cd5d4bddacb41623811ab318",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_row: 20370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1151-63d3e1fa3fcd>:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i, (pd_idx, row) in tqdm(enumerate(pd_10Q[pd_10Q.filing_date.dt.year==year].iterrows()), total=len(pd_10Q[pd_10Q.filing_date.dt.year==year])):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ad40618d8f4428bb8accc73dcc2c0c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20370.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1154-e09ed17ecdec>:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for i, doc_str in tqdm(enumerate(str_l), total=len(str_l)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c01f6cf67ea84b879ded680b4308982a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20370.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------- processing:  2016\n",
      "n_row: 19541\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "327d192102b2407cad6f91b62670d205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=19541.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afc65580161341e7aa56d57cd19cbe7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=19541.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------- processing:  2017\n",
      "\n"
     ]
    }
   ],
   "source": [
    "save_tmp(data_fp, 2016, 2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the start of section Item 2 by searching for interesting patterns. These patterns are discovered by trial and error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load temp results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1158,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = which_year\n",
    "s1_fname = data_fp + f'/tmp/filing_{year}.data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1159,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(s1_fname, 'rb') as f:\n",
    "    filing_str_l, pd_idx_l, idx_d = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of 10Q in this year\n",
    "n_docs = len(filing_str_l)\n",
    "#n_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filing_str_l[0][:1000]  # origin; \\n (new line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print one\n",
    "#print(filing_str_l[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View a document as a character sequence. \n",
    "\n",
    "Given a document and a particular subsequence of characters in the document, the span of the subsequence is a integer tuple  (𝑥,𝑦)  where  𝑥  marks the start position of the subsequence in the document while  𝑦  marks the end position."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 interesting types of spans for each document:\n",
    "\n",
    "+ The span of the title marking the start of Item 2(Part I).\n",
    "\n",
    "+ The span of the title marking the end of the desired content. \n",
    "\n",
    "`span_pd`: So prepare 2 columns in `span_pd` which stores the span values. \n",
    "\n",
    "`status_pd`: For each type of spans, it is possible that we can't find any matched subsequence. So `status_pd` records detailed failure information for debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame(a dict {i: [a list]})\n",
    "span_pd = pd.DataFrame.from_dict({i: [(0, 0), (0, 0)] for i in range(n_docs)}, orient='index')\n",
    "status_pd = pd.DataFrame.from_dict({i: [0, 0] for i in range(n_docs)}, orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "status codes: \n",
    "+ -1, uninitialized (doc not visited by the extract function, buggy case); \n",
    "+ 0, so far failed, and no clues of the reason; \n",
    "+ 1, succeeded; \n",
    "+ 2, promising, but need further check; \n",
    "+ 3, need special treatment;\n",
    "+ 4, has confirmed that there is no item 1 section;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0, 0)</td>\n",
       "      <td>(0, 0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       1\n",
       "0  (0, 0)  (0, 0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1\n",
       "0  0  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(span_pd.head(1), status_pd.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start of Item2\n",
    "\n",
    "Item 2. Management’s Discussion and Analysis of Financial Condition and Results of Operations. \n",
    "\n",
    "\n",
    "For letter:\n",
    "\n",
    "very common ones: `Item 2`, `ITEM 2`, `Item 2.`, `ITEM 2.`...\n",
    "1. number of space varys\n",
    "2. must locates in the head of a line\n",
    "3. after `item 2`, may be variational number of space, or \\n\n",
    "\n",
    "\n",
    "\n",
    "` MANAGEMENT S DISCUSSION AND ANALYSIS OF FINANCIAL CONDITION AND RESULTS OF OPERATIONS` (may have \\n inside this title)\n",
    "\n",
    "` Management s Discussion...`(may have \\n inside this title)\n",
    "\n",
    "`Management's...`\n",
    "\n",
    "\n",
    "\n",
    "For position:\n",
    "\n",
    "May find 1 or 2 positions (in index, there may be one); \n",
    "\n",
    "    + if =2, later one;\n",
    "    + if =0, error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ rule1; match: \n",
    "    - 1.lower case; `item 2`, `item no.2`\n",
    "    - 2.must at head of a line;\n",
    "    - 3.could possible followed by `,` `:` `.` `\\n` `\\-`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Watch Out, not all 10-Q documents contain item 2 (part 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IDEA:\n",
    "\n",
    "strict+general to strict+specific\n",
    "\n",
    "1. item 2 + literal\n",
    "\n",
    "2. literal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### estimate idx location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get loc of start of index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item 2 in context\n",
    "pattern_idx_st = re.compile(\"(^\\s*?|\\s{4,}|\\\\n+)((i)(tem)\\s*?n?o?\\s*?\\.?\\s*s?\\s*?)(2)\\s*?([,: .\\n\\-\\s]+)([a-zA-Z\\s\\,\\.]{0,50})\\s{1,}(Management|trustee)([a-zA-Z\\s\\']{1,10})\\s*?(Discussion)([a-zA-Z\\s]{10,90})(\\s{4,}|\\n+|\\.+)\", re.I|re.M) # the first time show \"item\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_index_loc(max_i):\n",
    "    idx_l = []\n",
    "    valid_ = 0\n",
    "    for i in tqdm(range(max_i)):\n",
    "        try:\n",
    "            loc_ = list(pattern_idx_st.finditer(filing_str_l[i]))[1].span(0)[0]\n",
    "            idx_l.append(loc_)\n",
    "            valid_ += 1\n",
    "        except:\n",
    "            continue\n",
    "    return idx_l\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locs = np.array(estimate_index_loc(3000))\n",
    "\n",
    "#print('idx_min = ',locs.min(),'\\n',\n",
    "#      '0.01q = ',np.quantile(locs,0.01) )\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get loc of end of index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not necessary to be very strict\n",
    "# using part I\n",
    "pattern_idx_end = re.compile(\"(^\\s*?|\\s{4,}|\\\\n+)(PART I)([,: .\\n\\-\\s]+)(\\s{4,}|\\n+|\\.+)\", re.I|re.M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_index_loc2(max_i):\n",
    "    idx_l2 = []\n",
    "    valid_ = 0\n",
    "    for i in tqdm(range(max_i)):\n",
    "        try:\n",
    "            loc_ = list(pattern_idx_end.finditer(filing_str_l[i]))[1].span(0)[0]\n",
    "            idx_l2.append(loc_)\n",
    "            valid_ += 1\n",
    "        except:\n",
    "            continue\n",
    "    return idx_l2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#locs2 = np.array(estimate_index_loc2(3000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1171,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#print('idx_min = ',locs2.min(),'\\n',\n",
    "#      '0.9q = ',np.quantile(locs2,0.9) )\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "90%, Content begining < 9273\n",
    "\n",
    "99%, item 2 start > 7945\n",
    "\n",
    "set threshhold as 8000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### begin of item 2 content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pattern 1: match item 2 + management or discussion\n",
    "\n",
    "pattern1 = re.compile(\"(^\\s*?|\\s{4,}|\\\\n+)((i)(tem)\\s*?n?o?\\s*?\\.?\\s*s?\\s*?)(2)\\s*?([,: .\\n\\-\\s]+)([a-zA-Z\\s\\,\\.]{0,50})\\s{1,}(((Management|trustee)([a-zA-Z\\s\\']{10,90}))|((discussion)([a-zA-Z\\s]{10,80})))(\\s{4,}|\\n+|\\.+)\", re.I|re.M)\n",
    "\n",
    "pattern1_1 = re.compile(\"item\", re.I|re.M)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pure literal, match \"management discussion and analysis of financial  CONDITION AND RESULTS OF OPERATIONS \"\n",
    "# case 1: do not write \"item 2\" before title\n",
    "# case 2: item 1, 2, 3, and 4....like this\n",
    "pattern2 = re.compile(\"(^\\s*?|\\s{4,}|\\\\n+)(Management|trustee)([a-zA-Z\\s\\']{1,10})\\s*?\\n*?(Discussion)(\\s+|\\n+)(and)(\\s+|\\n+)(analysis)(\\s+|\\n+)(of)(\\s+|\\n+)(financial)(\\s+|\\n+)(condition)(\\s+|\\n+)(and)(\\s+|\\n+)(results)(\\s+|\\n+)(of)(\\s+|\\n+)(operations)(\\s{2,}|\\n+|\\.+)\", re.I|re.M)\n",
    "pattern2_1 = re.compile(\"Management|trustee\", re.I|re.M)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1174,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def find_item2_start(i):\n",
    "    '''\n",
    "    finding the start of item 2 in ith document\n",
    "    \n",
    "    no return,\n",
    "    update span_pd[i,0] and status_pd[i,0]\n",
    "    '''\n",
    "    target = filing_str_l[i]\n",
    "    \n",
    "    # default using pattern 1 \n",
    "    finds_l = list(pattern1.finditer(target))\n",
    "    \n",
    "    if len(finds_l) > 1: # ideally, len should be 2; some times was split to multiple\n",
    "        if finds_l[1].span(0)[0] > 8000:\n",
    "            span_pd.loc[i, 0] = finds_l[1].span(0)  # begin with \"item\"   \n",
    "            status_pd.loc[i, 0] = 1\n",
    "        elif finds_l[1].span(0)[0] > 2500:\n",
    "            span_pd.loc[i, 0] = finds_l[1].span(0)    # update for further check\n",
    "            status_pd.loc[i, 0] = 2\n",
    "            print(f\"WARNING: hybrid, more than 2 found, location of item 2 < 8000 in filing_str_l[{i}]\") \n",
    "        else:\n",
    "            status_pd.loc[i, 0] = 3 # do not update\n",
    "            print(f\"FAIL: hybrid, more than 2 found, location of item 2 < 2500 in filing_str_l[{i}]\") \n",
    "\n",
    "    elif len(finds_l) == 1:\n",
    "        if finds_l[0].span(0)[0] > 8000:\n",
    "            span_pd.loc[i, 0] = finds_l[0].span(0)   \n",
    "            status_pd.loc[i, 0] = 1\n",
    "        elif finds_l[0].span(0)[0] > 2500:\n",
    "            span_pd.loc[i, 0] = finds_l[0].span(0)    # update anyway\n",
    "            status_pd.loc[i, 0] = 2\n",
    "            print(f\"WARNING: hybrid, only 1 found, location of item 2 < 8000, in filing_str_l[{i}]\")  \n",
    "        else:\n",
    "            status_pd.loc[i, 0] = 3 # do not update\n",
    "            print(f\"FAIL: hybrid, only 1 found, location of item 2 < 2500 in filing_str_l[{i}]\") \n",
    "    else:\n",
    "        # using literally match\n",
    "        finds_l = list(pattern2.finditer(target))            \n",
    "        if len(finds_l) >= 1:\n",
    "\n",
    "            if finds_l[0].span(0)[0] > 8000:\n",
    "                span_pd.loc[i, 0] = finds_l[0].span(0)  # get the 1st\n",
    "                status_pd.loc[i, 0] = 1\n",
    "            elif finds_l[0].span(0)[0] > 2500:\n",
    "                span_pd.loc[i, 0] = finds_l[0].span(0)    # update anyway\n",
    "                status_pd.loc[i, 0] = 2\n",
    "                print(f\"WARNING: literally, location of letter < 8000 in filing_str_l[{i}]\")   \n",
    "            else:\n",
    "                status_pd.loc[i, 0] = 3\n",
    "                print(f\"FAIL: literally, location of letter < 2500 in filing_str_l[{i}]\") \n",
    "        else:\n",
    "            status_pd.loc[i, 0] = -1\n",
    "            print(f'FAIL: no \"item2\" was found in filing_str_l[{i}]')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# refresh\n",
    "span_pd = pd.DataFrame.from_dict({i: [(0, 0), (0, 0)] for i in range(n_docs)}, orient='index')\n",
    "status_pd = pd.DataFrame.from_dict({i: [0, 0] for i in range(n_docs)}, orient='index')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1176-76bdfaea44a0>:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  update_tasks_s = [find_item2_start(i) for i in tqdm(range(len(filing_str_l[:300])))]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "815bb8f4a6494793a25042cf4b05d700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=300.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "update_tasks_s = [find_item2_start(i) for i in tqdm(range(len(filing_str_l[:300])))]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[#                                       ] | 2% Completed |  0.3sWARNING: hybrid, only 1 found, location of item 2 < 8000, in filing_str_l[57]\n",
      "FAIL: no \"item2\" was found in filing_str_l[107]\n",
      "WARNING: hybrid, only 1 found, location of item 2 < 8000, in filing_str_l[250]\n",
      "[##                                      ] | 6% Completed |  0.4sFAIL: no \"item2\" was found in filing_str_l[88]\n",
      "FAIL: no \"item2\" was found in filing_str_l[105]\n",
      "[#########                               ] | 24% Completed |  1.1sFAIL: no \"item2\" was found in filing_str_l[258]\n",
      "[#################                       ] | 43% Completed |  1.7sFAIL: hybrid, only 1 found, location of item 2 < 2500 in filing_str_l[252]\n",
      "[###################                     ] | 47% Completed |  1.8sWARNING: hybrid, only 1 found, location of item 2 < 8000, in filing_str_l[220]\n",
      "[#########################               ] | 64% Completed |  2.6sWARNING: hybrid, more than 2 found, location of item 2 < 8000 in filing_str_l[101]\n",
      "[#############################           ] | 74% Completed |  3.1sFAIL: no \"item2\" was found in filing_str_l[131]\n",
      "[################################        ] | 81% Completed |  3.3sFAIL: no \"item2\" was found in filing_str_l[25]\n",
      "[######################################  ] | 95% Completed |  3.9sWARNING: hybrid, more than 2 found, location of item 2 < 8000 in filing_str_l[232]\n",
      "[########################################] | 100% Completed |  4.0s\n"
     ]
    }
   ],
   "source": [
    "with ProgressBar():\n",
    "    dask.compute(update_tasks_s, num_workers=cpu_core*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no update recorded:          19241\n",
      "succeeded:                   288\n",
      "updated,          loc < 8000 :5\n",
      "marked as failed, loc < 2500: 1\n",
      "confirmed no item 2:          6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('no update recorded:          ', sum(status_pd[0] == 0), '\\n'\n",
    "      'succeeded:                   ', sum(status_pd[0] == 1), '\\n',\n",
    "      'updated,          loc < 8000 :',sum(status_pd[0] == 2),'\\n',\n",
    "      'marked as failed, loc < 2500: ', sum(status_pd[0] == 3), '\\n',\n",
    "      'confirmed no item 2:          ', sum(status_pd[0] == -1), '\\n',\n",
    "      sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "comfirmed no item 2: \n",
    "\n",
    "3 , 2654 , 62, 177, 355, 414,\n",
    "\n",
    "11 has splited\n",
    "\n",
    "355 no item 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### manually check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_check(check_l):\n",
    "    for i in check_l:  \n",
    "        yield i,'\\n',filing_str_l[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check_size = 5\n",
    "#check_list = np.random.choice(np.array(status_pd.loc[:,0][status_pd[0] == 3].index), size = check_size, replace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check = manual_check(check_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1182,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# run this\n",
    "#print(check.__next__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End of Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item 3.\n",
    "rule1 = re.compile(\"(^\\s*?|\\s{2,}|\\\\n+)((i)(tem)\\s*?n?o?\\s*?\\.?\\s*s?\\s*?)(3)\\s*?([,: .\\n\\-])([\\s\\-]*?)([a-zA-Z\\s\\,\\.]{0,50})\\s{1,}(((quantitative)([a-zA-Z\\s\\']{10,90}))|((qualitative)([a-zA-Z\\s]{10,80})))(\\s{4,}|\\n+|\\.+)\", re.I|re.M)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item 4.\n",
    "# sometimes, type wrong item (2, 3, 4T)\n",
    "rule2 = re.compile(\"(^\\s*?|\\s{2,}|\\\\n+)((i)(tem)\\s*?n?o?\\s*?\\.?\\s*s?\\s*?)(4|3|4T)\\s*?([,: .\\n\\-])([a-zA-Z\\s\\,\\.]{0,50})([\\s|\\-]*?)(((controls)([a-zA-Z\\s]{10,20}))|((procedures)))(\\s{4,}|\\n+|\\.+)\", re.I|re.M)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part 2\n",
    "rule3 = re.compile(\"(^\\s*?|\\s{2,}|\\\\n+)((part)\\s*?(ii))\\s*?([,: .\\n\\-])([\\s|\\-]*?)(other)\\s*?([,: .\\n\\-])(information)(\\s{4,}|\\n+|\\.+)\", re.I|re.M)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pure letter, item 3\n",
    "rule4a = re.compile(\"(^\\s*?|\\s{4,}|\\\\n+)(quantitative)(\\s+|\\n+)(and)(\\s+|\\n+)(qualitative)(\\s+|\\n+)(disclosures)(\\s+|\\n+)(about)(\\s+|\\n+)(market)(\\s+|\\n+)(risk)(\\s{2,}|\\n+|\\.+)\", re.I|re.M)\n",
    "# item 4\n",
    "rule4b = re.compile(\"(^\\s*?|\\s{4,}|\\\\n+)(controls)(\\s+|\\n+)(and)(\\s+|\\n+)(procedures)(\\s{2,}|\\n+|\\.+)\", re.I|re.M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1187,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = [rule1, rule2, rule3, rule4a, rule4b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_item3_loc(max_i):\n",
    "    idx_l2 = []\n",
    "    valid_ = 0\n",
    "    for i in tqdm(range(max_i)):\n",
    "        try:\n",
    "            loc_ = list(rule1.finditer(filing_str_l[i]))[1].span(0)[0]\n",
    "            idx_l2.append(loc_)\n",
    "            valid_ += 1\n",
    "        except:\n",
    "            continue\n",
    "    return idx_l2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locs_it3 = np.array(estimate_item3_loc(3000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1190,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('idx_min = ',locs_it3.min(),'\\n',\n",
    "#      '0.01q = ',np.quantile(locs_it3,0.01) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1191,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def find_item2_end(i):\n",
    "    target = filing_str_l[i]\n",
    "    \n",
    "    if status_pd.loc[i, 0] not in [1, 2]:\n",
    "        print(f\"ignore{i}\")\n",
    "    else:\n",
    "        for n_rule, rule in enumerate(rules):\n",
    "            finds_l = list(rule.finditer(target))\n",
    "            if len(finds_l) >= 1:\n",
    "                for k, mo in enumerate(finds_l): # mo means match object\n",
    "                    #print(mo.span(0)[0] ,\"\\n\", span_pd.loc[i, 0][0])\n",
    "                    #print(k,mo.span(0)[0],span_pd.loc[i, 0][0])\n",
    "                    if (mo.span(0)[0] > span_pd.loc[i, 0][0]):\n",
    "                        span_pd.loc[i, 1] = mo.span(0)\n",
    "                        status_pd.loc[i, 1] = 1 # success\n",
    "                        return\n",
    "                    elif (n_rule == len(rules)-1) & (k == len(finds_l)-1) & (mo.span(0)[0] <= span_pd.loc[i, 0][0]): # last mo\n",
    "                        status_pd.loc[i, 1] = 2 # further checking\n",
    "                        print(f'all match fail in filing_str_l[{i}]')\n",
    "                        break # try next rule\n",
    "            else:\n",
    "                continue # try next rule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1192,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_tasks_e = [find_item2_end(i) for i in range(len(filing_str_l[:300]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                                        ] | 0% Completed |  0.4signore258\n",
      "ignore25\n",
      "[#############                           ] | 34% Completed |  1.6signore107\n",
      "[###############                         ] | 39% Completed |  1.8signore131\n",
      "[####################                    ] | 50% Completed |  2.5signore105\n",
      "[########################                ] | 60% Completed |  3.1signore252\n",
      "[############################            ] | 70% Completed |  3.4signore88\n",
      "[########################################] | 100% Completed |  4.4s\n"
     ]
    }
   ],
   "source": [
    "with ProgressBar():\n",
    "    dask.compute(update_tasks_e, num_workers=cpu_core*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1194,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(28769, 28883)</td>\n",
       "      <td>(45462, 45542)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(48635, 48732)</td>\n",
       "      <td>(75427, 75512)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(28666, 28768)</td>\n",
       "      <td>(42607, 42683)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(20665, 20758)</td>\n",
       "      <td>(35146, 35222)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(10159, 10257)</td>\n",
       "      <td>(25283, 25354)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(88751, 88856)</td>\n",
       "      <td>(185870, 185948)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(72565, 72662)</td>\n",
       "      <td>(134006, 134077)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(47692, 47805)</td>\n",
       "      <td>(89147, 89233)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(30082, 30183)</td>\n",
       "      <td>(58277, 58351)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(26482, 26589)</td>\n",
       "      <td>(55222, 55320)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0                 1\n",
       "0  (28769, 28883)    (45462, 45542)\n",
       "1  (48635, 48732)    (75427, 75512)\n",
       "2  (28666, 28768)    (42607, 42683)\n",
       "3  (20665, 20758)    (35146, 35222)\n",
       "4  (10159, 10257)    (25283, 25354)\n",
       "5  (88751, 88856)  (185870, 185948)\n",
       "6  (72565, 72662)  (134006, 134077)\n",
       "7  (47692, 47805)    (89147, 89233)\n",
       "8  (30082, 30183)    (58277, 58351)\n",
       "9  (26482, 26589)    (55222, 55320)"
      ]
     },
     "execution_count": 1194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "span_pd.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1\n",
       "0  1  1\n",
       "1  1  1\n",
       "2  1  1\n",
       "3  1  1\n",
       "4  1  1\n",
       "5  1  1\n",
       "6  1  1\n",
       "7  1  1\n",
       "8  1  1\n",
       "9  1  1"
      ]
     },
     "execution_count": 1195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status_pd.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Results  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1196,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_pd['pd_idx'] = pd_idx_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pd_10q_idx</th>\n",
       "      <th>cik</th>\n",
       "      <th>filing_date</th>\n",
       "      <th>fye</th>\n",
       "      <th>sic</th>\n",
       "      <th>ffind</th>\n",
       "      <th>file_name</th>\n",
       "      <th>n_words</th>\n",
       "      <th>n_unique_words</th>\n",
       "      <th>org_index</th>\n",
       "      <th>company_name</th>\n",
       "      <th>file_hash</th>\n",
       "      <th>file_hash_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>763950</td>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>20150930</td>\n",
       "      <td>3823</td>\n",
       "      <td>37</td>\n",
       "      <td>10-X_C_2016-2018/2016/QTR1/20160104_10-Q_edgar...</td>\n",
       "      <td>8127</td>\n",
       "      <td>1144</td>\n",
       "      <td>943316</td>\n",
       "      <td>UNIVERSAL DETECTION TECHNOLOGY</td>\n",
       "      <td>0001078782-16-002115_3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>62234</td>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>20151126</td>\n",
       "      <td>7830</td>\n",
       "      <td>7</td>\n",
       "      <td>10-X_C_2016-2018/2016/QTR1/20160105_10-Q_edgar...</td>\n",
       "      <td>10023</td>\n",
       "      <td>1343</td>\n",
       "      <td>943326</td>\n",
       "      <td>MARCUS CORP</td>\n",
       "      <td>0001144204-16-074058_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pd_10q_idx     cik filing_date       fye   sic  ffind  \\\n",
       "0           0  763950  2016-01-04  20150930  3823     37   \n",
       "1           1   62234  2016-01-05  20151126  7830      7   \n",
       "\n",
       "                                           file_name  n_words  n_unique_words  \\\n",
       "0  10-X_C_2016-2018/2016/QTR1/20160104_10-Q_edgar...     8127            1144   \n",
       "1  10-X_C_2016-2018/2016/QTR1/20160105_10-Q_edgar...    10023            1343   \n",
       "\n",
       "   org_index                    company_name               file_hash  \\\n",
       "0     943316  UNIVERSAL DETECTION TECHNOLOGY  0001078782-16-002115_3   \n",
       "1     943326                     MARCUS CORP  0001144204-16-074058_1   \n",
       "\n",
       "   file_hash_count  \n",
       "0                1  \n",
       "1                1  "
      ]
     },
     "execution_count": 1197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_10Q.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1198,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get filing url\n",
    "pd_10Q['edgar_url'] = \"\"\n",
    "for i, row in pd_10Q.iterrows():\n",
    "    pd_10Q.loc[i, 'edgar_url'] = get_edgar_link(row['file_name'], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pd_10q_idx</th>\n",
       "      <th>cik</th>\n",
       "      <th>filing_date</th>\n",
       "      <th>fye</th>\n",
       "      <th>sic</th>\n",
       "      <th>ffind</th>\n",
       "      <th>file_name</th>\n",
       "      <th>n_words</th>\n",
       "      <th>n_unique_words</th>\n",
       "      <th>org_index</th>\n",
       "      <th>company_name</th>\n",
       "      <th>file_hash</th>\n",
       "      <th>file_hash_count</th>\n",
       "      <th>edgar_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39911</th>\n",
       "      <td>39911</td>\n",
       "      <td>1392694</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>20170331</td>\n",
       "      <td>7310</td>\n",
       "      <td>34</td>\n",
       "      <td>10-X_C_2016-2018/2018/QTR1/20180102_10-Q_edgar...</td>\n",
       "      <td>7864</td>\n",
       "      <td>1110</td>\n",
       "      <td>1001185</td>\n",
       "      <td>Surge Holdings, Inc.</td>\n",
       "      <td>0001493152-18-000030_1</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/139269...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39912</th>\n",
       "      <td>39912</td>\n",
       "      <td>1606364</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>20171031</td>\n",
       "      <td>1000</td>\n",
       "      <td>28</td>\n",
       "      <td>10-X_C_2016-2018/2018/QTR1/20180102_10-Q_edgar...</td>\n",
       "      <td>10664</td>\n",
       "      <td>1547</td>\n",
       "      <td>1001186</td>\n",
       "      <td>GARMATEX HOLDINGS LTD.</td>\n",
       "      <td>0001062993-17-005393_1</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/160636...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39913</th>\n",
       "      <td>39913</td>\n",
       "      <td>1619227</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>20170930</td>\n",
       "      <td>7370</td>\n",
       "      <td>34</td>\n",
       "      <td>10-X_C_2016-2018/2018/QTR1/20180102_10-Q_edgar...</td>\n",
       "      <td>6963</td>\n",
       "      <td>1009</td>\n",
       "      <td>1001187</td>\n",
       "      <td>Cloudweb, Inc.</td>\n",
       "      <td>0001640334-18-000029_1</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/161922...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pd_10q_idx      cik filing_date       fye   sic  ffind  \\\n",
       "39911       39911  1392694  2018-01-02  20170331  7310     34   \n",
       "39912       39912  1606364  2018-01-02  20171031  1000     28   \n",
       "39913       39913  1619227  2018-01-02  20170930  7370     34   \n",
       "\n",
       "                                               file_name  n_words  \\\n",
       "39911  10-X_C_2016-2018/2018/QTR1/20180102_10-Q_edgar...     7864   \n",
       "39912  10-X_C_2016-2018/2018/QTR1/20180102_10-Q_edgar...    10664   \n",
       "39913  10-X_C_2016-2018/2018/QTR1/20180102_10-Q_edgar...     6963   \n",
       "\n",
       "       n_unique_words  org_index            company_name  \\\n",
       "39911            1110    1001185    Surge Holdings, Inc.   \n",
       "39912            1547    1001186  GARMATEX HOLDINGS LTD.   \n",
       "39913            1009    1001187          Cloudweb, Inc.   \n",
       "\n",
       "                    file_hash  file_hash_count  \\\n",
       "39911  0001493152-18-000030_1                1   \n",
       "39912  0001062993-17-005393_1                1   \n",
       "39913  0001640334-18-000029_1                1   \n",
       "\n",
       "                                               edgar_url  \n",
       "39911  https://www.sec.gov/Archives/edgar/data/139269...  \n",
       "39912  https://www.sec.gov/Archives/edgar/data/160636...  \n",
       "39913  https://www.sec.gov/Archives/edgar/data/161922...  "
      ]
     },
     "execution_count": 1199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_10Q[pd_10Q.filing_date.dt.year==2018].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1200,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_fname = f'{data_fp}/Extracted/{which_year}/Extracted_Meta.csv'\n",
    "it2_file_init = f'{data_fp}/Extracted/{which_year}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_item2(fp, pd_10Q, filing_str_l):\n",
    "    if os.path.exists(f'{data_fp}/Extracted/{which_year}/'):\n",
    "        pass\n",
    "    else:\n",
    "        os.makedirs(f'{data_fp}/Extracted/{which_year}/')\n",
    "    print(\"saving item2 txt files .......\")\n",
    "    subpd = pd_10Q[pd_10Q.filing_date.dt.year == which_year].reset_index()\n",
    "    idx_start = subpd.loc[0, 'pd_10q_idx']\n",
    "    idx_end = subpd.shape[0] + idx_start\n",
    "    for i in tqdm(range(idx_start, idx_end)): # number of 10q for a year\n",
    "        j = idx_d[pd_10Q.loc[i, 'pd_10q_idx']]\n",
    "        if (status_pd.iloc[j, 0] in [1, 2]) & (status_pd.iloc[j, 1] in [1, 2]): # start and end both success\n",
    "            file_hash = pd_10Q['file_hash'][i]\n",
    "            start = span_pd.iloc[j, 0][0]\n",
    "            end = span_pd.iloc[j, 1][0]\n",
    "            doc_str = filing_str_l[j][start:end]\n",
    "            doc_str = re.sub('\\s+', ' ', doc_str)\n",
    "            if len(doc_str) > 200:\n",
    "                with open(it2_file_init+f\"item2_{file_hash}.txt\", \"w\") as f:\n",
    "                    f.write(doc_str)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
